# Classificador de Vagas
> 

## ğŸ§  VisÃ£o Geral

Este projeto Ã© um pipeline completo de Web Scraping + NLP + Machine Learning, desenvolvido para coletar publicaÃ§Ãµes do LinkedIn, tratÃ¡-las, remover duplicatas e classificar automaticamente:

    O tipo do post (vaga, postagem comum ou conteÃºdo estrangeiro)

    A senioridade da vaga (estÃ¡gio, jÃºnior, pleno, sÃªnior ou multi-nÃ­vel)

A soluÃ§Ã£o combina: 

    ExtraÃ§Ã£o automatizada com Selenium e BeautifulSoup.
      
    Limpeza e padronizaÃ§Ã£o dos dados.
      
    Embeddings com Sentence-BERT.
      
    Modelos de classificaÃ§Ã£o com RegressÃ£o LogÃ­stica
      
    Processo de deduplicaÃ§Ã£o baseado em similaridade textual.
      

O projeto estÃ¡ em fase de preparaÃ§Ã£o para deploy no portfÃ³lio, permitindo que qualquer usuÃ¡rio cole o link de uma vaga e receba uma anÃ¡lise automÃ¡tica em tempo real.

## ğŸ§¬ Arquitetura do Projeto
    ğŸ“ Classificador-de-vagas-NLP/
    â”‚
    â”œâ”€â”€ .venv/                         # Ambiente virtual
    â”œâ”€â”€ .python-version
    â”œâ”€â”€ pyproject.toml                 # ConfiguraÃ§Ã£o do projeto (UV/Python)
    â”œâ”€â”€ uv.lock
    â”œâ”€â”€ requirements.txt               # Requisitos do Projeto
    â”‚
    â”œâ”€â”€ model_train.py                 # Treinamento dos modelos
    â”œâ”€â”€ model_predict.py               # PrediÃ§Ã£o usando embeddings + regex
    â”œâ”€â”€ web_scraping.py                # Script geral de scraping (atalho)
    â”œâ”€â”€ README.md
    â”‚
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ raw/
    â”‚   â”‚   â”œâ”€â”€ posts_com_labels.xlsx  # Dataset rotulado manualmente (VersÃ£o Antiga, NÃ£o Ã© Mais Utilizado)
    â”‚   â”‚   â”œâ”€â”€ posts_linkedin.csv     # Dados brutos do scraper
    â”‚   â”‚   â””â”€â”€ posts_treino.xlsx      # Dataset Utilizado no Treino
    â”‚   â”‚
    â”‚   â”œâ”€â”€ processed/
    â”‚   â”‚   â”œâ”€â”€ posts_preditos.csv     # Resultado final das prediÃ§Ãµes
    â”‚   â”‚   â”œâ”€â”€ treino_label.csv       # Dataset Criado pelo Modelo 1 durante o Treinamento
    â”‚   â”‚   â””â”€â”€ treino_senioridade.csv # Dataset Criado pelo Modelo 2 durante o Treinamento
    â”‚   â”‚
    â”‚   â””â”€â”€ fixes/                     # Scripts auxiliares de manutenÃ§Ã£o
    â”‚       â”œâ”€â”€ atualizar_senioridade.py
    â”‚       â”œâ”€â”€ filtrar_e_juntar_datasets.py
    â”‚       â”œâ”€â”€ padronizar_todas_datas.py
    â”‚       â””â”€â”€ teste_filtro_duplicatas.py
    â”‚
    â”œâ”€â”€ graphs/
    â”‚   â”œâ”€â”€ Dashboard.png              # Imagem do dashboard Power BI
    â”‚   â””â”€â”€ graficos.pbix              # Arquivo original do Power BI
    â”‚
    â”œâ”€â”€ logs/                          # Logs do scraper / execuÃ§Ãµes
    â”‚
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ model_labels.pkl           # Modelo 1 (tipo do post)
    â”‚   â”œâ”€â”€ model_sen.pkl              # Modelo 2 (senioridade)
    â”‚   â””â”€â”€ encoder_regex.pkl          # Encoder one-hot dos regex
    â”‚
    â””â”€â”€ src/
        â”œâ”€â”€ nlp/
        â”‚   â””â”€â”€ model_utils.py         # Embeddings, combine_embeddings, training utils
        â”‚
        â””â”€â”€ scraping/
            â”œâ”€â”€ post_scraper.py        # FunÃ§Ã£o principal de scraping
            â””â”€â”€ scraping_utils.py
                â”œâ”€â”€ cookies.json           # Cookies salvos do LinkedIn
                â”œâ”€â”€ cookies.py             # GestÃ£o de cookies do scraper
                â”œâ”€â”€ csv_storage.py         # Salvamento incremental em CSV
                â”œâ”€â”€ driver_setup.py        # ConfiguraÃ§Ã£o do Selenium WebDriver
                â”œâ”€â”€ extract_post_information.py # Parsing do HTML bruto
                â”œâ”€â”€ filtrar_posts_duplicados.py # Filtro de duplicaÃ§Ã£o
                â”œâ”€â”€ post_filters.py        # Configura o filtro de busca
                â”œâ”€â”€ scrolling.py           # LÃ³gica de scroll automÃ¡tico
                â”œâ”€â”€ text_cleaning.py       # Limpeza de texto + extraÃ§Ã£o via regex
                â””â”€â”€ waits.py               # Aguardos especÃ­ficos do scraper

## ğŸ•¸ï¸ 1. Coleta de Dados (LinkedIn)

A extraÃ§Ã£o Ã© feita com <strong>Selenium WebDriver</strong> e <strong>BeautifulSoup4</strong> que coletam:

    Autor
    
    Texto
    
    Hashtags
    
    Link da publicaÃ§Ã£o
    
    LocalizaÃ§Ã£o
    
    Data (incluindo datas relativas como â€œ1 semâ€, â€œhÃ¡ 3 hâ€)

Foi criada uma funÃ§Ã£o completa que converte datas relativas em datas absolutas no formato YYYY-MM-DD.

## ğŸ§¼ 2. Limpeza e PadronizaÃ§Ã£o

    NormalizaÃ§Ã£o de texto
    
    RemoÃ§Ã£o de HTML
    
    PadronizaÃ§Ã£o de datas
    
    Limpeza de hashtags
    
    Tratamento de campos vazios
    
    UnificaÃ§Ã£o do formato textual do dataset

## ğŸ§¹ 3. DeduplicaÃ§Ã£o AvanÃ§ada

O LinkedIn frequentemente repete vagas ou republica conteÃºdo quase idÃªntico.

O pipeline remove duplicaÃ§Ãµes em duas etapas:

    1. Duplicatas exatas (texto + data)
    2. Similaridade TF-IDF (> 0.92)

Usando:

    TF-IDF Vectorizer
    
    Cosine Similarity
    
    NormalizaÃ§Ã£o textual

Resultado da deduplicaÃ§Ã£o:

    Dataset original: 1264 posts
    95 removidos por texto+data
    163 removidos por similaridade (>0.92)
    Total removidos: 258
    Dataset final: 1006 posts Ãºnicos

## ğŸ§  4. Embeddings com Sentence-BERT

Modelo utilizado:

    sentence-transformers/all-MiniLM-L6-v2

Geramos embeddings para:

    autor
    
    texto
    
    hashtags

E concatenamos:

    X = [emb_author | emb_text | emb_hash]

## ğŸ·ï¸ 5. Modelo 1 â€” ClassificaÃ§Ã£o do Tipo de Post

Classes:

    vaga
    
    postagem
    
    estrangeiro

Modelo: Logistic Regression

Resultados:

|Tipo|PrecisÃ£o|Recall|F1-Score|
|:---:|:---:|:---:|:---:|
|Estrangeiro|0.90|0.79|0.84|
|Postagem|0.88|0.82|0.85|
|Vaga|0.88|0.94|0.91|

## ğŸ¯ 6. Modelo 2 â€” ClassificaÃ§Ã£o de Senioridade

Classes:

    Estagio
    
    Junior
    
    Pleno
    
    Senior

    Multi (MÃºltiplas Vagas na Postagem)

âœ” Features utilizadas:

    embeddings (S-BERT)
    
    regex_onehot (junior/pleno/senior/estagio/multi)

Comparativo da performance apÃ³s limpeza do dataset e inclusÃ£o do regex:

|Classe |F1 Antes|F1 Depois|DiferenÃ§a|
|:---:|:---:|:---:|:---:|
|EstÃ¡gio|0.00|0.83|+83 pontos|
|JÃºnior|0.34|0.61|+27 pontos|
|Pleno|0.53|0.70|+17 pontos|
|SÃªnior|0.33|0.77|+44 pontos
|Multi|0.84|0.77|-7 Pontos|           

## ğŸ”® 7. Pipeline de PrediÃ§Ã£o
O script model_predict.py:

    Carrega o modelo de embeddings

    Carrega os modelos de labels e senioridade

    Carrega o OneHotEncoder salvo no treinamento

    Gera embeddings + regex â†’ one-hot

    Concatena embeddings e features

    Faz prediÃ§Ã£o do tipo de post

    Se for vaga â†’ prediÃ§Ã£o da senioridade

    Salva em data/processed/posts_preditos.csv

## ğŸ“Š 8. Dashboard Power BI

<img width="1431" height="805" alt="Dashboard" src="https://github.com/user-attachments/assets/0d3b1707-2211-4455-8ca2-142c582bec03" />

Inclui:

    Total de Posts

    GrÃ¡fico em Rosquinha da distribuiÃ§Ã£o de tipos de posts
    
    Total de Vagas por Senioridade

    Tabela com Texto e Link das Vagas

    Total de Posts Por Data
    
    Hashtags mais presentes

Dataset utilizado: posts_preditos.csv.

## ğŸŒ 9. Deploy no PortfÃ³lio (em construÃ§Ã£o)

A pÃ¡gina do portfÃ³lio contarÃ¡ com input para colar o link de uma vaga

Endpoint Flask que:
    
    Recebe o link
    
    Roda scraping da vaga
    
    Limpa e normaliza texto
    
    Gera embeddings

    Prediz tipo + senioridade + probabilidade

    Retorna JSON para o front-end

ApresentaÃ§Ã£o visual com:

    Tipo do post
    
    Senioridade prevista
      
    Hashtags
      
    Presencial/HÃ­brido/Remoto
      
    Storytelling do projeto
      
    AnimaÃ§Ãµes e gifs (scraping, embeddings, matrix, etc.)

## ğŸ 10. ConclusÃ£o

Este projeto representa um pipeline completo e profissional de NLP, Web Scraping, Machine Learning e Deploy, reunindo:

    Engenharia de dados
    
    Limpeza e deduplicaÃ§Ã£o inteligente
    
    Embeddings modernos
    
    Modelos de classificaÃ§Ã£o multietapas
    
    IntegraÃ§Ã£o futura com pÃ¡gina web
    
    Storytelling completo para portfÃ³lio
